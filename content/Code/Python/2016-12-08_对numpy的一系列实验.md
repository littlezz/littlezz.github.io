Title: 对numpy的一系列实验  
Tags: python, numpy


本文主要总结了如何把numpy计算速度优化100倍的过程。  


简介
----

最近要对图片做二值化， 参照[Adaptive Thresholding Using the Integral Image][1] 这篇论文， 可是Python的for循环非常的慢，单纯的翻译伪代码实现起来速度要比C慢接近100倍， 论文上的实现对640x480的图片用时大概为15ms， 接下来我们要一步步从最初的慢100倍优化到和C一样快， 以及最后再比它快一点点。

算法
----
首先， 介绍一下 Adaptive Thresholding Using the Integral Image 这篇论文， 论文很简单， 对一个点周围的一片区域取平均值， 如果该点低于平均值的85%， 就设为黑， 否则为白色。 论文主要是用累积和来改进取一片区域平均值的速度。 
过程为水平方向做一次累积和， 垂直方向做一次累积和， 这样每一个点就表示其左上角的区域的和， 于是要计算一个矩形（a, b, c, d), 其区域上的和就是 d - b -c + a. 
原始的扫描区域的每一个点求和， 时间是O(n * n * boxsize * boxsize)， 现在变成了常数时间。  


直观实现
------
首先我们直接照着原理实现，理论是最快的
（然而实际是最慢的） 

```python
def intuitive_method(mat, w, h , set_value, threshold, boxsize):
    mat = mat.T
    integral_map = np.zeros_like(mat, dtype=int)
    ret = np.zeros_like(mat, dtype=int)
    for i in range(w):
        csum=0
        for j in range(h):
            csum += mat[i, j]
            if i > 0:
                integral_map[i,j] = integral_map[i-1, j] + csum
            else:
                integral_map[i,j] = csum

    half_s = (boxsize-1) // 2
    for i in range(w):
        for j in range(h):
            x1 = max(i - half_s, 0)
            x2 = min(i+half_s, w - 1)
            y1 = max(j-half_s, 0)
            y2 = min(j + half_s, h - 1)
            field_sum = integral_map[x2, y2] - integral_map[x1, y2] - integral_map[x2, y1] + integral_map[x1, y1]
            count =  (x2-x1)*(y2-y1)
            if (mat[i,j] * count)*100 < field_sum*(100-threshold):
                ret[i,j] = set_value
            else:
                ret[i,j] = set_value ^ 255

    return ret.astype(np.uint8).T
```
mat是我们的图片矩阵， boxsize是区域的长度， 必须是奇数。 
每个点都在周围取一个boxsize长度的矩形， 要特别处理边界， 让他不要超出累积矩阵。  
很直观的代码， 纯翻译自论文里面的伪代码。  

看看速度：

```
⇒  python3 implement.py
Image shape 640x480
intuitive_method take 1658.280885 ms  
```
1600ms, （怎么和说好的15ms不一样）。


改进的直观方法
------------


```python
def optimized_intuitive_method(mat, w, h , set_value, threshold, boxsize):
    mat = mat.T
    integral_map = np.zeros_like(mat, dtype=int)
    ret = np.zeros_like(mat, dtype=int)
    np.cumsum(mat, 0, out=integral_map)
    np.cumsum(integral_map, 1, out=integral_map)

    half_s = boxsize >> 1
    inv_value = set_value ^ 255
    for i in range(w):
        for j in range(h):
            x1 = max(i - half_s, 0)
            x2 = min(i + half_s, w - 1)
            y1 = max(j - half_s, 0)
            y2 = min(j + half_s, h - 1)
            field_sum = integral_map.item(x2, y2) - integral_map.item(x1, y2) - integral_map.item(x2, y1) + integral_map.item(x1, y1)
            count =  (x2-x1)*(y2-y1)
            if (mat.item(i,j) * count)*100 < field_sum*(100-threshold):
                ret.itemset(i, j, set_value)
            else:
                ret.itemset(i, j, inv_value)

    return ret.astype(np.uint8).T
```

Numpy提供了item和itemset方法来加速对矩阵上单个点的操作。  
同时两次累积和实际可以用可以用`np.cumsum`来计算， 但是这里有一个小细节，  
单纯的使用两次`a=np.cumsum(...)`会额外进行一次内部的内存拷贝， 我们要指定`out`参数来阻止多余的内存拷贝.

在计算half_s的时候， 使用移位`boxsize >> 1`来加速。  

```
⇒  python3 implement.py
Image shape 640x480
optimized_intuitive_method take 823.928799 ms
```
快了一倍， 但是还是不够


猥琐法
-----
不妨让我们直接退化到累积和的优化之前，纯粹的暴力计算，所有计算都交给opencv， 看看会发生什么事情。


```python
def opencv_way(mat, w, h , set_value, threshold, boxsize):
    mat = mat.astype(int)
    inv_value = set_value ^ 255
    kernel = np.ones((boxsize, boxsize)) * (100-threshold)/100 / (boxsize*boxsize)
    result = cv.filter2D(mat, -1, kernel)
    ret = np.where(mat < result, [set_value], [inv_value])
    return ret.astype(np.uint8)
```

这是时间：

```
⇒  python3 implement.py
Image shape 640x480
opencv_way take 35.920926 ms
```

好了， 可以全剧终了。  
简单的6行代码， 纯粹的暴力美学。 速度快了40倍。（你学到了么？）  
这里我们借助opencv 的 `filter2D`方法， 自己定义了一个kernel， 用来求一个点周围区域的平均值， 接下来的计算就全部交给opencv了。   
关于opencv， 有一点需要补充， **opencv表示， numpy是辣鸡， 请多使用opencv自带的函数**。  



向量化
-----
还不能全剧终， 接下来是重点， numpy是为矩阵计算而生的， 我们前面一直按照C的思维来对单个点做操作， 而且for循环的存在导致速度下降太多， 接下来我们要寻求把for循环替换掉， 改成向量的计算。

对于numpy来说， 比如我有两个2维矩阵A和B， 要计算两个矩阵上所有点的差， 从速度上来说， 
 
```
A - B > A[i] - B[i] > A[i,j] - B[i,j]
```

我们现在希望把所有的for循环， 替换为矩阵的计算 `A - B`

一开始的时候我想到利用一次for循环， 从上往下计算两行之间的值， 接着从左往右计算每一列的值， 但是这样只能去掉一个for循环， 后来我想了2个晚上， 想通了实际上所有等距离点操作都可以转化为等距离的向量操作， 进而可以通过构造矩阵来进行矩阵间的操作。  


对于之前的代码， 计算累积和部分已经很好了， 关键之后的计算， 代码冗余， 效率低下。  

其中造成整个for循环存在的关键因素是下面这句代码

```
integral_map[x2, y2] - integral_map[x1, y2] - integral_map[x2, y1] + integral_map[x1, y1]
```
而实际上， 这些点之间是等距离的， （boxsize的距离）， 也就是说， 每一个点对应的x1， x2, y1, y2 都是固定的， 我们可以构造出4个矩阵， 分别向左上， 右上， 左下， 右下位移一段距离， 
这样就可以吧整个for循环计算化简成  

```
D + A - C - B
```


那么怎么构造出这些矩阵呢？  
想象一下， 把`integral_map[x1, y1]`当成一个集合， 记为A， `integral_map[x1, y2]`的集合记为B， `integral_map[x2, y1]`的集合记为C，`integral_map[x2, y2]`记为D。   

以构造A为例， A实际上是对原先的矩阵向上和向左平移了一半的boxsize的距离， 比如对于矩阵右下角的点，A对应于 `integral_map[h-half_boxsize, w-half_boxsize]`  

但是对于左上角的点， 超出了累积矩阵的范围， 为了避免额外的对边界的判断， 我们要额外构造出边框。  

想象一下， 比如我们有一个5x5的矩阵， boxsize取3, 

```
  0 1 2 3 4
0 * * * * *
1 * * * * *
2 * * * * *
3 * * * * *
4 * * * * *
```  
计算 (2, 2) 的时候， 取 (1, 1), (1, 3)， （3，1）， （3，3）四个点  
计算(0,0)上的和的时候， 右下角取（1，1）， 左上角超出了边界，所以只能取（0，0）  
计算（0，1）的时候，右下角是（1，2） 但是左上角还是（0，0）    

所以我们可以构造出一个`(boxsize-1)/2` 长度的边框，边框上的值和边界的值一样。 这样我们可以通过平移得到ABCD四个矩阵， 而不用额外的边界判断。 

```python
def vector_method(mat, w, h, set_value, threshold, boxsize):
    inv_value = set_value ^ 255
    integral_map = np.zeros_like(mat, dtype=int)

    np.cumsum(mat,0, out=integral_map)
    np.cumsum(integral_map, 1, out=integral_map)

    half_s = boxsize >> 1
    big_mat = cv.copyMakeBorder(integral_map, half_s, half_s, half_s, half_s, borderType=cv.BORDER_REPLICATE)
    big_h, big_w = big_mat.shape
    # 构造4个矩阵
    # top left
    A = big_mat[:h, :w]
    # bottom left
    B = big_mat[big_h - h:, :w]
    # top right
    C = big_mat[:h, big_w - w:]
    # bottom right
    D = big_mat[big_h - h:, big_w - w:]

    COUNT = get_count_matrix(w, h, boxsize)
    result = (D + A - B - C)*((100-threshold)/100) / COUNT
    ret = np.where(mat < result, [set_value], [inv_value])
    return ret.astype(np.uint8)
```
但是， 现在还有一道阴影笼罩着我们， 我们没有办法得到窗口的实际大小。 边界附近的点上的窗口是变化的， 我们得额外构造出一个矩阵`COUNT`来表示每个点上的窗口大小。  

```python
def get_count_matrix(w, h, boxsize):
    """
    矩阵上每个点的值表示该点上的窗口覆盖的总点数。
    """

    # faster than (boxsize-1) // 2
    half_boxsize = (boxsize) >> 1
    
    # 窗口的真正大小并不是boxsize！而是（boxsize - 1）！
    A = np.ones((h, w)) * (boxsize-1)
    B = np.ones((h, w)) * (boxsize-1)

    for i in range(half_boxsize):
        value = i + half_boxsize
        A[i, :] = value
        A[-1-i, :] = value
        B[:, i] = value
        B[:, -1-i] = value

    return A * B
```

看一下所需的时间

```
⇒  python3 implement.py
Image shape 640x480
vector_method take 22.166661 ms
```

现在我们比最初快了80倍， 已经接近论文上的理论速度了， 但是`get_count_matrix`函数显得非常的力不从心， 还可以寻找优化的办法。  

优化后的向量化方法
---------------
回想之前的整个过程， 我们对边界的处理实际上过于保守了， 导致计算窗口覆盖点数的时候过于小心翼翼了(不然boxsize-1是怎么得出来的， 都是泪啊)。

我们可以在计算累积和之前先对边界翻折来进行填充， 之后再对扩展后的矩阵进行累积和，这样可以省略掉`get_count_matrix`函数， 统一采用`(boxsize-1)*(boxsize-1)`。  

```python
def optimized_vector_method(mat, w, h, set_value, threshold, boxsize):
    inv_value = set_value ^ 255
    half_s = boxsize >> 1
    integral_map = cv.copyMakeBorder(mat, half_s, half_s, half_s, half_s, borderType=cv.BORDER_REFLECT101)
    integral_map = integral_map.astype(np.uint32)

    integral_map.cumsum(0, out=integral_map)
    integral_map.cumsum(1, out=integral_map)

    big_h, big_w = integral_map.shape
    # 构造4个矩阵
    # top left
    A = integral_map[:h, :w]
    # bottom left
    B = integral_map[big_h - h:, :w]
    # top right
    C = integral_map[:h, big_w - w:]
    # bottom right
    D = integral_map[big_h - h:, big_w - w:]

    # COUNT = get_count_matrix(w, h, boxsize)
    COUNT = (boxsize-1)**2
    result = (D + A - B - C) * ((100-threshold) / 100) / COUNT
    ret = np.where(mat < result, [set_value], [inv_value])
    return ret.astype(np.uint8)
```

看看计算时间，  

```
⇒  python3 implement.py
Image shape 640x480
optimized_vector_method take 10.539570999999999 ms

```

比最初快了150倍， 而且超过了论文上的C语言实现的15ms的时间。  


总结分析
-------
对于最后的这个方法， 需要额外解释一下为什么会比论文快。  
其中一个是CPU的原因， 论文上用的是4核奔腾3.4Ghz的CPU，而我自己的是i5 2.7GHz。  
i5应该是快一些的， （我猜）

之后是在对窗口大小的计算时间上， 因为我们通过填充扩展矩阵， 使得每一个点的窗口大小都是固定的值， 比论文中的方法省去了多余的窗口大小计算和多余的边界判断。  
但是扩展矩阵在计算累积和的时候有额外的时间消耗， boxsize默认采用边长的1/8， 
构造后的矩阵比原先大了 81/64 倍的大小。  
不过在之后的计算中并没有额外的消耗。  

再次， 虽然我们构造出了4个矩阵ABCD， 但是实际上没有对内存做拷贝， ABCD都是累积和矩阵上的映射， 没有对内存中的实际数据做拷贝。

最后，   

```
integral_map = integral_map.astype(np.uint32)
``` 
我指定了矩阵中的元素的大小， 统一为无符号32位， 速度又得到了一定的提升。  
但是uint32有其局限， 只能存下2^32次方的数据， 灰度图的每一个点的最大取值是2^8， 于是uint32的累积矩阵只能存下2^24个像素点， 然而由于填充了边框， 矩阵比实际大了81/64， 约1.266倍， `sqrt(2^24/1.266) = 3640`,  所以只能处理3640x3640的图片， 但是从平均情况来说， 每一个点平均取2^7， 于是我们可以处理最大5148x5148的图片。


到此， 完成了从最初的1600ms到10ms的优化。  


彩蛋
----

混沌邪恶  

```python
import cv2 as cv

def wtf(mat, w, h , set_value, threshold, boxsize):
    # 这才叫Python嘛！
    return cv.adaptiveThreshold(mat, 255, cv.ADAPTIVE_THRESH_GAUSSIAN_C, cv.THRESH_BINARY_INV, boxsize, 20)
```

咕咕咕？？？  
我选择opencv自带的局部自适应高斯二值化

```
⇒  python3 implent.py
Image shape 640x480
wtf take 8.884578000000001 ms

```


[1]:http://people.scs.carleton.ca/~roth/iit-publications-iti/docs/gerh-50002.pdf